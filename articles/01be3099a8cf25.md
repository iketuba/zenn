---
title: "機械学習 ~モデルの評価~"
emoji: "🐕"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["python", "機械学習", "初心者", "プログラミング"]
published: false
---
# 初めに
この記事ではモデルの評価について説明します。
環境はgoogle colabotoryを使っています。
今回はkaggleのMelbourne Housing Snapshotのmelb_data.csvというデータを用います。
https://www.kaggle.com/datasets/dansbecker/melbourne-housing-snapshot

# モデルの評価の説明の前に
モデルの評価について説明する前に、まずは
- データを読み込む
- 欠損値を削除する
- 目的変数を取り出す
- 説明変数として量的変数のみを抽出する

というところまでやってしまいます。より詳しい説明は[こちらの記事](https://zenn.dev/python3654/articles/971f589c968b41)を参考にして下さい。(パスはダウンロードしたフォルダを指定して下さい。)
```py
import pandas as pd

melb_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/datasets/melb_data.csv')
melb_data = melb_data.dropna(axis=0)

y = melb_data['Price']
X = melb_data.drop(['Price'], axis=1)
X = X.select_dtypes(include=['number'])
```

# モデルの評価
予測モデルを作成する主な目的は、手元にあるデータを学習することでデータの特徴をつかみ、未知のデータが与えられたときに高い精度で予測できるようにすることです。未知のデータに対する予測性能のことを汎化性能といいます。モデルの汎化性能を良くするには、モデルの汎化性能を知ることが必要です。例えば、モデルAとモデルBを作ったときに、モデルの性能を測る方法がなければどちらのモデルを採用するべきか分かりません。一般的に、手元にあるデータを学習用のデータと評価用のデータに分割して、評価用データへの予測性能を何らかの性能指標を用いてスコアとして表します。このようにデータを分割して評価することを交差検証(クロスバリデーション)といいます。交差検証には様々な手法がありますが、ここではホールドアウト法について説明します。

# ホールドアウト法
ホールドアウト法では、まず手元のデータを学習用のデータと評価用のデータに分割します。これには、scikit-learnの[train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split)を用います。引数のtest_sizeを例えば0.3に指定すると評価用のデータの割合を3割にすることができます。またrandom_stateを指定すると、分割の結果が固定されます。
ここで、tr_X, va_X, tr_y, va_yは、それぞれ学習用データの説明変数、評価用データの説明変数、学習用データの目的変数、評価用データの目的変数を表しています。
```py
from sklearn.model_selection import train_test_split

tr_X, va_X, tr_y, va_y = train_test_split(X, y, test_size=0.3, random_state = 0)
```

次に、学習用データのみを用いて学習を行います。ここでは、[DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor)を用いています。これにより、学習用データの説明変数と目的変数の関係性を学習したモデルが出来上がります。
```py
from sklearn.tree import DecisionTreeRegressor

model = DecisionTreeRegressor(random_state=0)
model.fit(tr_X, tr_y)
```

さらに、このモデルに評価用のデータの説明変数を入力して予測値を出力します。
```py
va_pred = model.predict(va_X)
```

最後に、この予測値の精度を性能指標を用いてスコアとして表します。性能指標もたくさんの種類がありますが、ここでは平均絶対誤差(MAE: Mean Absolute Error)を用います。平均絶対誤差とは、各データに対して予測値と正解値の差の絶対値を計算し、その総和をデータ数で割った値です。これにはscikit-learnの[mean_absolute_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error)を用います。一つ目の引数には正解値(今回はva_y)、二つ目の引数には予測値(va_pred)を渡します。
```py
from sklearn.metrics import mean_absolute_error

mean_absolute_error(va_y, va_pred)
```
・出力
250864.24690693922